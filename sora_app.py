import streamlit as st
import requests
import time
import json
import os
import base64
import asyncio
import io
import math
from PIL import Image # å›¾ç‰‡å¤„ç†æ ¸å¿ƒåº“
from datetime import datetime
import edge_tts
from moviepy.editor import VideoFileClip, AudioFileClip

# ================= é…ç½®åŒºåŸŸ =================
# API_KEY = "sk-xxx"  <-- è¿™ä¸€è¡Œåˆ æ‰æˆ–æ³¨é‡Šæ‰
API_KEY = st.secrets["API_KEY"]  # <-- æ”¹æˆè¿™ä¸€è¡Œï¼ä»åå°è¯»å–å¯†ç 
HOST = "https://grsai.dakka.com.cn"

# æ™ºè°± AI é…ç½® (ç”¨äºå†™è„šæœ¬)
LLM_API_KEY = "f87cd651378147b58a12828ad95465ee.9yUBYWw6o3DIGWKW" 
LLM_BASE_URL = "https://open.bigmodel.cn/api/paas/v4"     
LLM_MODEL = "glm-4-flash"                                 
# ===============================================

st.set_page_config(page_title="Sora è§†é¢‘å·¥åŠ v8.6", layout="wide", page_icon="ğŸ¬")

# === ğŸ—£ï¸ è¯­éŸ³åº“ ===
VOICE_MAP = {
    "English (è‹±è¯­)": "en-US-ChristopherNeural",
    "Chinese (ä¸­æ–‡)": "zh-CN-YunxiNeural",
    "Malay (é©¬æ¥è¯­)": "ms-MY-OsmanNeural",
    "Indonesian (å°å°¼è¯­)": "id-ID-ArdiNeural",
    "Vietnamese (è¶Šå—è¯­)": "vi-VN-NamMinhNeural",
    "Thai (æ³°è¯­)": "th-TH-NiwatNeural",
    "Filipino (è²å¾‹å®¾è¯­)": "fil-PH-AngeloNeural"
}

# === ğŸ› ï¸ æ ¸å¿ƒåŠŸèƒ½ ===

# 1. ğŸ”¥ğŸ”¥ğŸ”¥ æ™ºèƒ½æ‹¼å›¾å¼•æ“ (è‡ªåŠ¨å¤„ç† 1-9 å¼ å›¾)
def stitch_images_to_base64(uploaded_files):
    if not uploaded_files: return None, None
    try:
        images = [Image.open(f) for f in uploaded_files]
        count = len(images)
        
        # å•å¼ å›¾ç›´æ¥è¿”å›
        if count == 1:
            buffered = io.BytesIO()
            images[0].save(buffered, format="PNG")
            return images[0], f"data:image/png;base64,{base64.b64encode(buffered.getvalue()).decode('utf-8')}"

        # å¤šå¼ å›¾ï¼šè®¡ç®—ç½‘æ ¼ (ä¾‹å¦‚ 6å¼  -> 3åˆ—x2è¡Œ)
        cols = math.ceil(math.sqrt(count))
        rows = math.ceil(count / cols)
        
        # ç»Ÿä¸€æŠŠæ‰€æœ‰å›¾ç‰‡ç¼©æ”¾åˆ° 512x512 ä»¥ä¾¿æ‹¼æ¥ (ä¿æŒæ¯”ä¾‹å±…ä¸­)
        cell_size = 512
        grid_w = cols * cell_size
        grid_h = rows * cell_size
        
        # åˆ›å»ºç™½åº•å¤§ç”»å¸ƒ
        new_image = Image.new('RGB', (grid_w, grid_h), (255, 255, 255))
        
        for idx, img in enumerate(images):
            # è®¡ç®—å½“å‰æ ¼å­çš„ä½ç½®
            r = idx // cols
            c = idx % cols
            x = c * cell_size
            y = r * cell_size
            
            # ç¼©æ”¾å›¾ç‰‡é€‚åº”æ ¼å­
            img.thumbnail((cell_size, cell_size))
            # å±…ä¸­ç²˜è´´
            paste_x = x + (cell_size - img.width) // 2
            paste_y = y + (cell_size - img.height) // 2
            new_image.paste(img, (paste_x, paste_y))
            
        # è½¬ Base64
        buffered = io.BytesIO()
        new_image.save(buffered, format="PNG")
        img_str = base64.b64encode(buffered.getvalue()).decode('utf-8')
        
        return new_image, f"data:image/png;base64,{img_str}"
        
    except Exception as e:
        st.error(f"æ‹¼å›¾å‡ºé”™: {e}")
        return None, None

# 2. LLM å†™è„šæœ¬
def generate_timed_script(product_name, target_lang):
    if "xxxx" in LLM_API_KEY:
        return None, "âŒ è¯·é…ç½®æ™ºè°± API Key"
        
    headers = {
        "Authorization": f"Bearer {LLM_API_KEY}",
        "Content-Type": "application/json"
    }
    system_prompt = (
        "You are a professional video scriptwriter. "
        "Write a concise product narration script strictly for a **15-second video**. "
        "Structure: Hook -> Benefit -> CTA. "
        f"Output must be in {target_lang} ONLY."
    )
    user_prompt = f"Product: {product_name}. Write a 15s sales script in {target_lang}."
    
    payload = {
        "model": LLM_MODEL,
        "messages": [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}],
        "temperature": 0.7
    }
    try:
        res = requests.post(f"{LLM_BASE_URL}/chat/completions", headers=headers, json=payload, timeout=15)
        if res.status_code == 200:
            return res.json()['choices'][0]['message']['content'].strip(), None
        else:
            return None, f"API Error: {res.text}"
    except Exception as e:
        return None, str(e)

# 3. TTS ç”Ÿæˆ
async def generate_tts_audio(text, voice, output_filename):
    communicate = edge_tts.Communicate(text, voice)
    await communicate.save(output_filename)

# 4. éŸ³ç”»åˆæˆ
def merge_video_audio(video_path, audio_path, output_path):
    try:
        video_clip = VideoFileClip(video_path)
        audio_clip = AudioFileClip(audio_path)
        final_audio = audio_clip
        if audio_clip.duration > video_clip.duration:
            final_audio = audio_clip.subclip(0, video_clip.duration)
        final_clip = video_clip.set_audio(final_audio)
        final_clip.write_videofile(output_path, codec='libx264', audio_codec='aac', logger=None)
        video_clip.close()
        audio_clip.close()
        return True
    except: return False

# 5. API æäº¤
def check_result(task_id):
    url = f"{HOST}/v1/draw/result"
    headers = {"Authorization": f"Bearer {API_KEY}"}
    try:
        return requests.post(url, headers=headers, json={"task_id": task_id}, timeout=30).json()
    except Exception as e:
        return {"error": str(e)}

def submit_video_task(prompt, model, aspect_ratio, duration, size, img_data=None):
    url = f"{HOST}/v1/video/sora-video"
    headers = {"Authorization": f"Bearer {API_KEY}", "Content-Type": "application/json"}
    payload = {
        "prompt": prompt, "model": model, "aspect_ratio": aspect_ratio, "duration": duration, "size": size, "expand_prompt": True
    }
    if img_data: payload["url"] = img_data
    try:
        return requests.post(url, headers=headers, json=payload, timeout=60).json()
    except Exception as e:
        return {"error": str(e), "data": None}

# === ä¾§è¾¹æ  ===
with st.sidebar:
    st.markdown("### ğŸ“œ å†å²è®°å½•")
    st.info("ğŸ’¡ **v8.6 æ–°ç‰¹æ€§**ï¼šæ”¯æŒå¤šå›¾è‡ªåŠ¨æ‹¼è´´ï¼Œä¸€æ¬¡æ€§è®© AI çœ‹æ¸…äº§å“ 6 ä¸ªè§’åº¦ï¼")

# === ä¸»ç•Œé¢ ===
st.markdown("## ğŸ­ Sora è§†é¢‘å·¥åŠ <span style='font-size:0.8rem; color:red'>v8.6 (ç»ˆæèåˆç‰ˆ)</span>", unsafe_allow_html=True)

col1, col2 = st.columns([1, 1.5])

# --- å·¦ä¾§ï¼šè®¾ç½® ---
with col1:
    st.subheader("1. åŸºç¡€è®¾ç½®")
    target_lang_label = st.selectbox("ç›®æ ‡è¯­è¨€", list(VOICE_MAP.keys()))
    voice_code = VOICE_MAP[target_lang_label]
    lang_name = target_lang_label.split("(")[0].strip()
    
    product_name = st.text_input("äº§å“åç§°", placeholder="ä¾‹å¦‚ï¼šç¾ç™½ç‰™è†")

    st.markdown("---")
    st.subheader("2. è§†è§‰ä¸å¬è§‰")
    
    # è§†è§‰æŒ‡ä»¤
    visual_script = st.text_area(
        "ğŸ¥ è§†è§‰è„šæœ¬ (Visual)", 
        placeholder="ä¾‹å¦‚ï¼šèµ›åšæœ‹å…‹é£æ ¼ï¼Œç‰¹å†™é•œå¤´å±•ç¤ºäº§å“ç»†èŠ‚...",
        height=100
    )

    # å£æ’­æ–‡æ¡ˆ
    c_gen, c_txt = st.columns([1, 3])
    with c_gen:
        if st.button("âœ¨ è‡ªåŠ¨å†™ç¨¿", use_container_width=True):
            if not product_name:
                st.error("ç¼ºäº§å“å")
            else:
                with st.spinner("ç”Ÿæˆä¸­..."):
                    script, err = generate_timed_script(product_name, lang_name)
                    if script:
                        st.session_state['gen_script_15s'] = script
                        st.success("å·²ç”Ÿæˆ")
                    else:
                        st.error(err)
    with c_txt:
        voice_text = st.text_area("ğŸ—£ï¸ å£æ’­æ–‡æ¡ˆ (Audio)", value=st.session_state.get('gen_script_15s', ""), height=100)
    
    st.markdown("---")
    st.subheader("3. å¤šå›¾ä¸Šä¼  (è‡ªåŠ¨æ‹¼å›¾)")
    
    # ğŸ”¥ æ ¸å¿ƒï¼šæ”¯æŒå¤šé€‰
    uploaded_files = st.file_uploader("æ‹–å…¥å¤šå¼ äº§å“å›¾ (æœ€å¤š9å¼ )", type=['png', 'jpg', 'jpeg'], accept_multiple_files=True)
    
    # ğŸ”¥ é¢„è§ˆæ‹¼å›¾æ•ˆæœ
    stitched_preview = None
    final_base64 = None
    if uploaded_files:
        with st.spinner("æ­£åœ¨æ™ºèƒ½æ‹¼å›¾..."):
            stitched_preview, final_base64 = stitch_images_to_base64(uploaded_files)
        if stitched_preview:
            st.image(stitched_preview, caption=f"ğŸ§© å·²å°† {len(uploaded_files)} å¼ å›¾æ‹¼åˆæˆä¸€å¼ å‚è€ƒå›¾", use_column_width=True)

    # å‚æ•°
    c1, c2 = st.columns(2)
    with c1: batch_ratio = st.selectbox("æ¯”ä¾‹", ["16:9", "9:16", "1:1"])
    with c2: size_label = st.selectbox("ç”»è´¨", ["é«˜æ¸… (Large)", "æ ‡å‡† (Small)"])
    batch_size = "large" if "é«˜æ¸…" in size_label else "small"

    start_btn = st.button("ğŸš€ å¼€æ‹ (éŸ³ç”»åˆä¸€)", type="primary", use_container_width=True, disabled=len(uploaded_files)==0)

# --- å³ä¾§ï¼šç›‘è§†å™¨ ---
with col2:
    st.subheader("ğŸ¬ å¯¼æ¼”ç›‘è§†å™¨")
    
    if start_btn:
        if not visual_script or not voice_text:
            st.error("è¯·å®Œå–„è„šæœ¬ä¿¡æ¯ï¼")
        else:
            final_prompt = (
                f"Target Language: {lang_name}.\n\n"
                f"## PART 1: VISUAL DIRECTIVES\n"
                f"Subject: {product_name}.\n"
                f"Visual Style: {visual_script}.\n"
                f"Reference Image: The provided image is a GRID showing multiple angles of the product. Please maintain consistency with these views.\n\n"
                f"## PART 2: AUDIO CONTEXT\n"
                f"Narrative Script: '{voice_text}'.\n"
                f"Requirement: Characters must appear to be speaking {lang_name}."
            )
            
            with st.status("æ­£åœ¨åˆ¶ç‰‡ä¸­...", expanded=True) as status:
                status.write("ğŸ§© æ‹¼å›¾å‚è€ƒå·²ä¸Šä¼ ...")
                
                # 1. è§†é¢‘
                status.write("ğŸ¥ Sora æ­£åœ¨æ¸²æŸ“ç”»é¢...")
                res = submit_video_task(final_prompt, "sora-2", batch_ratio, 15, batch_size, final_base64)
                task_id = res.get("data", {}).get("task_id") or res.get("task_id")
                
                if task_id:
                    video_url = None
                    bar = status.progress(0)
                    for i in range(60):
                        time.sleep(3)
                        check = check_result(task_id)
                        s = check.get("data", {}).get("status")
                        bar.progress(min(i*2+10, 90))
                        if s in ["SUCCESS", "COMPLETED", "succeeded"]:
                            d = check.get("data", {})
                            if d.get("results"): video_url = d["results"][0].get("url")
                            if not video_url: video_url = d.get("url")
                            break
                        elif s in ["FAILED", "failed"]:
                            st.error("è§†é¢‘ç”Ÿæˆå¤±è´¥")
                            st.stop()
                    
                    # 2. éŸ³é¢‘
                    if video_url:
                        status.write("ğŸ—£ï¸ å½•åˆ¶å£æ’­ä¸­...")
                        os.makedirs("temp", exist_ok=True)
                        audio_path = f"temp/{task_id}.mp3"
                        video_path = f"temp/{task_id}.mp4"
                        final_path = f"temp/{task_id}_final.mp4"
                        
                        try:
                            asyncio.run(generate_tts_audio(voice_text, voice_code, audio_path))
                            with open(video_path, 'wb') as f:
                                f.write(requests.get(video_url).content)
                            
                            status.write("ğŸï¸ å‰ªè¾‘åˆæˆä¸­...")
                            if merge_video_audio(video_path, audio_path, final_path):
                                status.update(label="âœ… å‡ºç‰‡æˆåŠŸï¼", state="complete")
                                st.success("ğŸ‰ æ‚¨çš„äº§å“å¤§ç‰‡å·²å®Œæˆï¼")
                                st.video(final_path)
                                with open(final_path, "rb") as f:
                                    st.download_button("â¬‡ï¸ ä¸‹è½½åŸç‰‡", f, file_name=f"Product_Ad_{task_id}.mp4")
                            else:
                                st.error("åˆæˆå¤±è´¥")
                        except Exception as e:
                            st.error(f"å¤„ç†é”™è¯¯: {e}")
                else:
                    st.error(f"æäº¤å¤±è´¥: {res}")

    elif st.session_state.get('view_mode') == 'history_video':
        rec = st.session_state['current_record']
        st.info(f"å›çœ‹ï¼š{rec.get('product')}")
        st.video(rec.get('video_url'))

    else:
        st.markdown("""
        <div style='background:#f0f2f6; padding:20px; border-radius:10px; color:gray; text-align:center'>
            ğŸ‘‹ è¯·æ‹–å…¥äº§å“å¤šè§’åº¦å›¾ç‰‡ï¼Œå¼€å§‹ç”Ÿæˆ
        </div>
        """, unsafe_allow_html=True)
