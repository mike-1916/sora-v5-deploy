import streamlit as st
import requests
import time
import json
import os
import base64
import asyncio
import io
import math
from PIL import Image
from datetime import datetime
import edge_tts
from moviepy.editor import VideoFileClip, AudioFileClip

# ================= é…ç½®åŒºåŸŸ =================
# API_KEY = "sk-xxx"  <-- è¿™ä¸€è¡Œåˆ æ‰æˆ–æ³¨é‡Šæ‰
API_KEY = st.secrets["API_KEY"]  # <-- æ”¹æˆè¿™ä¸€è¡Œï¼ä»åå°è¯»å–å¯†ç 
HOST = "https://grsai.dakka.com.cn" 

LLM_API_KEY = "f87cd651378147b58a12828ad95465ee.9yUBYWw6o3DIGWKW" 
LLM_BASE_URL = "https://open.bigmodel.cn/api/paas/v4"     
LLM_MODEL = "glm-4-flash"                                 
# ===============================================

st.set_page_config(page_title="Sora è§†é¢‘å·¥åŠ v8.8", layout="wide", page_icon="ğŸ›¡ï¸")

# === ğŸ› ï¸ æ ¸å¿ƒåŠŸèƒ½ ===

# 1. æ‹¼å›¾
def stitch_images_to_base64(uploaded_files):
    if not uploaded_files: return None, None
    try:
        images = [Image.open(f) for f in uploaded_files]
        count = len(images)
        if count == 1:
            buffered = io.BytesIO()
            images[0].save(buffered, format="PNG")
            return images[0], f"data:image/png;base64,{base64.b64encode(buffered.getvalue()).decode('utf-8')}"
        
        cols = math.ceil(math.sqrt(count))
        rows = math.ceil(count / cols)
        cell_size = 512
        new_image = Image.new('RGB', (cols * cell_size, rows * cell_size), (255, 255, 255))
        
        for idx, img in enumerate(images):
            r = idx // cols
            c = idx % cols
            img.thumbnail((cell_size, cell_size))
            new_image.paste(img, (c * cell_size + (cell_size - img.width)//2, r * cell_size + (cell_size - img.height)//2))
            
        buffered = io.BytesIO()
        new_image.save(buffered, format="PNG")
        return new_image, f"data:image/png;base64,{base64.b64encode(buffered.getvalue()).decode('utf-8')}"
    except: return None, None

# 2. å†™è„šæœ¬
def generate_timed_script(product_name, target_lang, duration_sec):
    if "xxxx" in LLM_API_KEY:
        return None, "âŒ è¯·é…ç½®æ™ºè°± API Key"
    headers = {"Authorization": f"Bearer {LLM_API_KEY}", "Content-Type": "application/json"}
    
    length_guide = "Short (20-30 words)" if duration_sec <= 10 else "Standard (40-50 words)"
    system_prompt = f"Write a {duration_sec}s video script in {target_lang}. {length_guide}. Hook->Benefit->CTA."
    user_prompt = f"Product: {product_name}."
    
    try:
        res = requests.post(f"{LLM_BASE_URL}/chat/completions", headers=headers, json={
            "model": LLM_MODEL, "messages": [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}], "temperature": 0.7
        }, timeout=15)
        return res.json()['choices'][0]['message']['content'].strip(), None
    except Exception as e: return None, str(e)

# 3. TTS
async def generate_tts_audio(text, voice, output_filename):
    communicate = edge_tts.Communicate(text, voice)
    await communicate.save(output_filename)

# 4. åˆæˆ (å¢åŠ å®¹é”™)
def merge_video_audio(video_path, audio_path, output_path):
    try:
        video_clip = VideoFileClip(video_path)
        audio_clip = AudioFileClip(audio_path)
        final_audio = audio_clip
        if audio_clip.duration > video_clip.duration:
            final_audio = audio_clip.subclip(0, video_clip.duration)
        final_clip = video_clip.set_audio(final_audio)
        final_clip.write_videofile(output_path, codec='libx264', audio_codec='aac', logger=None)
        video_clip.close()
        audio_clip.close()
        return True
    except Exception as e:
        print(f"åˆæˆæŠ¥é”™: {e}") # æ‰“å°é”™è¯¯åˆ°åå°
        return False

# 5. API æäº¤
def check_result(task_id):
    url = f"{HOST}/v1/draw/result"
    headers = {"Authorization": f"Bearer {API_KEY}"}
    try:
        return requests.post(url, headers=headers, json={"task_id": task_id}, timeout=30).json()
    except Exception as e:
        return {"error": str(e)}

def submit_video_task(prompt, model, aspect_ratio, duration, size, img_data=None):
    url = f"{HOST}/v1/video/sora-video"
    headers = {"Authorization": f"Bearer {API_KEY}", "Content-Type": "application/json"}
    payload = {"prompt": prompt, "model": model, "aspect_ratio": aspect_ratio, "duration": duration, "size": size, "expand_prompt": True}
    if img_data: payload["url"] = img_data
    try:
        return requests.post(url, headers=headers, json=payload, timeout=60).json()
    except Exception as e:
        return {"error": str(e), "data": None}

# === ğŸ’¾ å†å²è®°å½• ===
HISTORY_FILE = "history.json"
def load_history():
    if not os.path.exists(HISTORY_FILE): return []
    try:
        with open(HISTORY_FILE, "r", encoding="utf-8") as f: return json.load(f)
    except: return []

def save_to_history(record):
    history = load_history()
    if any(h.get('task_id') == record['task_id'] for h in history): return
    history.append(record)
    with open(HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False, indent=2)

# === ä¾§è¾¹æ  ===
with st.sidebar:
    st.markdown("### ğŸ“œ å†å²è®°å½•")
    history_list = load_history()
    if not history_list: st.info("æš‚æ— è®°å½•")
    else:
        for item in reversed(history_list):
            label = f"ğŸ¥ {item.get('time', '')[5:-3]} | {item.get('product')}"
            with st.expander(label):
                if st.button("å›çœ‹", key=f"btn_{item['task_id']}"):
                    st.session_state['view_mode'] = 'history_video'
                    st.session_state['current_record'] = item

# === ä¸»ç•Œé¢ ===
st.markdown("## ğŸ­ Sora è§†é¢‘å·¥åŠ <span style='font-size:0.8rem; color:red'>v8.8 (ç¨³å¥é˜²ä¸¢ç‰ˆ)</span>", unsafe_allow_html=True)

col1, col2 = st.columns([1, 1.5])

VOICE_MAP = {
    "English (è‹±è¯­)": "en-US-ChristopherNeural",
    "Chinese (ä¸­æ–‡)": "zh-CN-YunxiNeural",
    "Malay (é©¬æ¥è¯­)": "ms-MY-OsmanNeural",
    "Indonesian (å°å°¼è¯­)": "id-ID-ArdiNeural",
    "Vietnamese (è¶Šå—è¯­)": "vi-VN-NamMinhNeural",
    "Thai (æ³°è¯­)": "th-TH-NiwatNeural",
    "Filipino (è²å¾‹å®¾è¯­)": "fil-PH-AngeloNeural"
}

with col1:
    st.subheader("1. åŸºç¡€è®¾ç½®")
    target_lang_label = st.selectbox("ç›®æ ‡è¯­è¨€", list(VOICE_MAP.keys()))
    voice_code = VOICE_MAP[target_lang_label]
    lang_name = target_lang_label.split("(")[0].strip()
    product_name = st.text_input("äº§å“åç§°", placeholder="ä¾‹å¦‚ï¼šç¾ç™½ç‰™è†")

    st.markdown("---")
    c1, c2, c3 = st.columns(3)
    with c1: batch_dur = int(st.selectbox("æ—¶é•¿", ["5s", "10s", "15s"]).replace("s",""))
    with c2: batch_ratio = st.selectbox("æ¯”ä¾‹", ["16:9", "9:16", "1:1"])
    with c3: 
        size_label = st.selectbox("ç”»è´¨", ["é«˜æ¸… (Large)", "æ ‡å‡† (Small)"])
        batch_size = "large" if "é«˜æ¸…" in size_label else "small"

    st.markdown("---")
    visual_script = st.text_area("ğŸ¥ è§†è§‰è„šæœ¬", placeholder="ç‰¹å†™å±•ç¤º...", height=80)
    
    c_gen, c_txt = st.columns([1, 2])
    with c_gen:
        if st.button(f"âœ¨ ç”Ÿæˆ {batch_dur}s æ–‡æ¡ˆ", use_container_width=True):
            if not product_name: st.error("ç¼ºäº§å“å")
            else:
                with st.spinner("ç”Ÿæˆä¸­..."):
                    script, err = generate_timed_script(product_name, lang_name, batch_dur)
                    if script: st.session_state['gs'] = script; st.success("å·²ç”Ÿæˆ")
                    else: st.error(err)
    with c_txt:
        voice_text = st.text_area("ğŸ—£ï¸ å£æ’­æ–‡æ¡ˆ", value=st.session_state.get('gs', ""), height=100)
    
    st.markdown("---")
    uploaded_files = st.file_uploader("æ‹–å…¥å¤šå¼ å›¾ç‰‡", type=['png', 'jpg', 'jpeg'], accept_multiple_files=True)
    stitched_preview, final_base64 = None, None
    if uploaded_files:
        stitched_preview, final_base64 = stitch_images_to_base64(uploaded_files)
        if stitched_preview: st.image(stitched_preview, caption="æ‹¼å›¾é¢„è§ˆ", use_column_width=True)

    start_btn = st.button(f"ğŸš€ ç”Ÿæˆ {batch_dur}s è§†é¢‘", type="primary", use_container_width=True, disabled=len(uploaded_files)==0)

with col2:
    st.subheader("ğŸ¬ è¿›åº¦ç›‘æ§")
    if start_btn:
        if not visual_script or not voice_text:
            st.error("è„šæœ¬ä¿¡æ¯ä¸å…¨")
        else:
            final_prompt = f"Language: {lang_name}. Duration: {batch_dur}s. Visual: {visual_script}. Audio Context: {voice_text}."
            
            with st.status(f"æ­£åœ¨åˆ¶ä½œ...", expanded=True) as status:
                status.write("ğŸ¥ æ­£åœ¨æ¸²æŸ“ç”»é¢...")
                res = submit_video_task(final_prompt, "sora-2", batch_ratio, batch_dur, batch_size, final_base64)
                task_id = res.get("data", {}).get("task_id") or res.get("task_id")
                
                if task_id:
                    video_url = None
                    bar = status.progress(0)
                    for i in range(60):
                        time.sleep(3)
                        check = check_result(task_id)
                        s = check.get("data", {}).get("status")
                        bar.progress(min(i*2+10, 95))
                        if s in ["SUCCESS", "COMPLETED", "succeeded"]:
                            d = check.get("data", {})
                            if d.get("results"): video_url = d["results"][0].get("url")
                            if not video_url: video_url = d.get("url")
                            break
                        elif s in ["FAILED", "failed"]:
                            st.error(f"Sora ç”Ÿæˆå¤±è´¥: {check.get('msg')}")
                            st.stop()
                    
                    if video_url:
                        # ğŸ”¥ğŸ”¥ğŸ”¥ æ”¹è¿›ç‚¹ï¼šæ‹¿åˆ°è§†é¢‘é“¾æ¥åï¼Œç«‹å³å±•ç¤ºï¼Œé˜²æ­¢åé¢åˆæˆæŠ¥é”™å¯¼è‡´å•¥éƒ½çœ‹ä¸åˆ°
                        status.write("âœ… ç”»é¢ç”ŸæˆæˆåŠŸï¼æ­£åœ¨å°è¯•é…éŸ³åˆæˆ...")
                        st.info("ğŸ‘‡ è¿™æ˜¯ Sora ç”Ÿæˆçš„åŸå§‹ç”»é¢ (æ— å£°ç‰ˆ)")
                        st.video(video_url) # å…ˆå±•ç¤ºæ— å£°ç‰ˆä¿åº•
                        
                        # å°è¯•åˆæˆéŸ³é¢‘
                        os.makedirs("temp", exist_ok=True)
                        audio_path = f"temp/{task_id}.mp3"
                        video_path = f"temp/{task_id}.mp4"
                        final_path = f"temp/{task_id}_final.mp4"
                        
                        try:
                            # ä¸‹è½½è§†é¢‘
                            v_data = requests.get(video_url).content
                            with open(video_path, 'wb') as f: f.write(v_data)
                            
                            # ç”ŸæˆéŸ³é¢‘
                            asyncio.run(generate_tts_audio(voice_text, voice_code, audio_path))
                            
                            # åˆæˆ
                            if merge_video_audio(video_path, audio_path, final_path):
                                status.update(label="ğŸ‰ å®Œç¾å‡ºç‰‡ï¼", state="complete")
                                st.success("âœ… æœ‰å£°åˆæˆç‰ˆå·²å°±ç»ªï¼š")
                                st.video(final_path) # å±•ç¤ºæœ‰å£°ç‰ˆ
                                
                                with open(final_path, "rb") as f:
                                    st.download_button("â¬‡ï¸ ä¸‹è½½æœ‰å£°è§†é¢‘", f, file_name=f"Final_{task_id}.mp4")
                            else:
                                status.update(label="âš ï¸ åˆæˆå¤±è´¥ (æ˜¾ç¤ºåŸç‰‡)", state="error")
                                st.warning("éŸ³é¢‘åˆæˆå¤±è´¥ (å¯èƒ½ç¼ºå°‘ ffmpeg)ï¼Œè¯·ç›´æ¥ä¸‹è½½ä¸Šæ–¹çš„ã€æ— å£°åŸç‰‡ã€‘ã€‚")
                                
                        except Exception as e:
                            status.update(label="âš ï¸ å¤„ç†å‡ºé”™", state="error")
                            st.error(f"åˆæˆè¿‡ç¨‹æŠ¥é”™: {e}")
                        
                        # æ— è®ºå¦‚ä½•éƒ½ä¿å­˜è®°å½•
                        save_to_history({
                            "task_id": task_id, "product": product_name, 
                            "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                            "video_url": video_url, "script": voice_text
                        })
                    else:
                        st.error("æœªèƒ½è·å–è§†é¢‘ URL")
                else:
                    st.error(f"æäº¤å¤±è´¥: {res}")

    elif st.session_state.get('view_mode') == 'history_video':
        rec = st.session_state['current_record']
        st.info(f"å›çœ‹ï¼š{rec.get('product')}")
        st.video(rec.get('video_url'))
        st.caption(f"è„šæœ¬ï¼š{rec.get('script')}")

    else:
        st.markdown("<div style='text-align:center; color:gray; padding:20px;'>ğŸ‘‹ å‡†å¤‡å°±ç»ª</div>", unsafe_allow_html=True)


